def __init__(self, logger):
    self.classes = CLASSES
    self.logger = logger
    self.logger.info("---------------DETECTION_Model Loading---------------")
    
    # Load ONNX model
    providers = ['CPUExecutionProvider']  # Add 'CUDAExecutionProvider' for GPU
    self.session = ort.InferenceSession('path/to/your/model.onnx', providers=providers)
    
    # Load project params for preprocessing
    with open('projects/abhil.yml', 'r') as f:
        self.params = yaml.safe_load(f)
    
    self.input_name = self.session.get_inputs()[0].name
    self.logger.info("---------------DETECTION_Model Loaded---------------")



def preprocess_image(self, image_path_or_array, max_size):
    """Preprocess image for ONNX model"""
    from utils.utils import preprocess  # Import from your utils
    
    if isinstance(image_path_or_array, np.ndarray):
        # Save temp image if numpy array
        temp_path = 'temp_image.jpg'
        cv2.imwrite(temp_path, image_path_or_array)
        ori_imgs, framed_imgs, framed_metas = preprocess(
            temp_path, max_size=max_size, 
            mean=self.params['mean'], std=self.params['std']
        )
        os.remove(temp_path)  # Clean up
    else:
        ori_imgs, framed_imgs, framed_metas = preprocess(
            image_path_or_array, max_size=max_size,
            mean=self.params['mean'], std=self.params['std']
        )
    
    return ori_imgs, framed_imgs, framed_metas



def DetectImage(self, image, thresh=0.05, short=768):
    """
    Detect objects using ONNX model with built-in postprocessing
    """
    input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]
    compound_coef = 2  # Adjust based on your model
    
    # Preprocess image
    ori_imgs, framed_imgs, framed_metas = self.preprocess_image(image, input_sizes[compound_coef])
    
    # Prepare input for ONNX
    x = framed_imgs[0]
    x = np.expand_dims(x, axis=0)  # Add batch dimension
    x = np.transpose(x, (0, 3, 1, 2))  # Convert to NCHW format
    
    # Run ONNX inference
    boxes, scores, classes = self.session.run(None, {self.input_name: x})
    
    Items = []
    
    # Process detections
    for i in range(len(boxes)):
        if scores[i] >= thresh:
            box = boxes[i]
            score = float(scores[i])
            class_id = int(classes[i])
            
            # Convert [x1,y1,x2,y2] to original image coordinates
            # Apply inverse transformation
            scale = framed_metas[0]['scale']
            pad_h = framed_metas[0]['pad_h'] 
            pad_w = framed_metas[0]['pad_w']
            
            x1 = (box[0] - pad_w) / scale
            y1 = (box[1] - pad_h) / scale  
            x2 = (box[2] - pad_w) / scale
            y2 = (box[3] - pad_h) / scale
            
            # Convert to integer coordinates
            xmin, ymin, xmax, ymax = int(x1), int(y1), int(x2), int(y2)
            
            Items.append({
                "class": self.classes[class_id],
                "bbox": [ymin, ymax, xmin, xmax],
                "score": str(round(score, 4))
            })
    
    # Rest of the function remains the same...
    det_data = Items
    self.logger.info(f"DETECTION DATA IS {det_data}")
    src_img_bytes = self.convert_image_to_file_bytes(image)
    final_det_rec_data = det_data
    
    # OCR processing code remains unchanged...
    try:
        file_text = get_text_from_doc(src_img_bytes, self.logger)
        signature_det_rec_data = get_signature_Names(file_text, image, det_data, self.logger)
        self.logger.info(f"Signature Name Extraction after parsing to AZURE-OCR is {signature_det_rec_data}")
        final_det_rec_data = signature_det_rec_data
    except Exception as e:
        self.logger.debug(f"Got an exception while extracting signature name from azure-doc-analyzer \n Exception: {str(e)}")
        final_det_rec_data = det_data

    try:
        chop_det_rec_data = get_chop_extraction(image, final_det_rec_data, self.logger)
        self.logger.info(f"Chop Extraction after parsing to AZURE-OCR is {chop_det_rec_data}")
        final_det_rec_data = chop_det_rec_data
    except Exception as e:
        self.logger.debug(f"Got an exception while extracting chop data from azure-doc-analyzer \n Exception: {str(e)}")
        return final_det_rec_data
    
    return final_det_rec_data
